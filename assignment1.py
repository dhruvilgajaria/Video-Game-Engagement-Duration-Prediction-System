# -*- coding: utf-8 -*-
"""assignment1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zXZkdeH1A5DmHdGpHYmji8zxR8SyU_ux

Part 1
"""

import gzip
from collections import defaultdict
import random
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split

# Function to read data
def readJSON(path):
    for l in gzip.open(path, 'rt', encoding="utf-8"):
        d = eval(l)
        u = d['userID']
        g = d['gameID']
        yield u, g, d

# Load data
dataset = []
for u, g, d in readJSON("/content/train.json.gz"):
    dataset.append((u, g, d))
    d["played"] = 1  # Mark as played

# Split data into training and validation sets
train = dataset[:165000]
valid = dataset[165000:]

# Function to balance the validation set with negative samples
def get_balanced_set(dataset, s):
    all_games = set()
    user_played = defaultdict(set)

    for user, game, review in dataset:
        all_games.add(game)
        user_played[user].add(game)

    negative = []
    for user, _, _ in s:
        not_played = all_games - user_played[user]
        new_game = random.choice(list(not_played))
        negative.append((user, new_game, {"played": 0}))

    return s + negative

class BayesianPRModel(tf.keras.Model):
    def __init__(self, num_factors, regularization, all_item_ids, all_user_ids):
        super(BayesianPRModel, self).__init__()
        # Initialize model parameters
        self.item_bias = tf.Variable(tf.random.normal([len(all_item_ids)], stddev=0.001))
        self.user_factors = tf.Variable(tf.random.normal([len(all_user_ids), num_factors], stddev=0.001))
        self.item_factors = tf.Variable(tf.random.normal([len(all_item_ids), num_factors], stddev=0.001))
        # Regularization coefficient
        self.regularization_coeff = regularization

    # Prediction for an individual user-item pair
    def predict_single(self, user_id, item_id):
        default_bias = self.avg_item_bias
        default_user_factor = self.avg_user_factor
        default_item_factor = self.avg_item_factor

        user_factor = self.user_factors[user_id] if user_id is not None else default_user_factor
        item_bias = self.item_bias[item_id] if item_id is not None else default_bias
        item_factor = self.item_factors[item_id] if item_id is not None else default_item_factor

        prediction = item_bias + tf.tensordot(user_factor, item_factor, axes=1)
        return prediction

    # Regularization term
    def regularization_term(self):
        return self.regularization_coeff * (tf.nn.l2_loss(self.item_bias) +
                                            tf.nn.l2_loss(self.user_factors) +
                                            tf.nn.l2_loss(self.item_factors))

    # Calculating the BPR score
    def bpr_score(self, users, items):
        user_tensor = tf.convert_to_tensor(users, dtype=tf.int32)
        item_tensor = tf.convert_to_tensor(items, dtype=tf.int32)

        beta_i = tf.nn.embedding_lookup(self.item_bias, item_tensor)
        gamma_u = tf.nn.embedding_lookup(self.user_factors, user_tensor)
        gamma_i = tf.nn.embedding_lookup(self.item_factors, item_tensor)

        x_ui = beta_i + tf.reduce_sum(tf.multiply(gamma_u, gamma_i), axis=1)
        return x_ui

    # Model's call method
    def call(self, users, positive_items, negative_items):
        x_ui = self.bpr_score(users, positive_items)
        x_uj = self.bpr_score(users, negative_items)
        return -tf.reduce_mean(tf.math.log(tf.math.sigmoid(x_ui - x_uj)))

    # Finalize averages for prediction
    def finalize_model(self):
        self.avg_item_bias = np.mean(self.item_bias.numpy(), axis=0)
        self.avg_user_factor = np.mean(self.user_factors.numpy(), axis=0)
        self.avg_item_factor = np.mean(self.item_factors.numpy(), axis=0)

class GamePlayPredictor:

    def __init__(self):
        self.user_index = {}
        self.game_index = {}

    def train_model(self, data, num_factors=5, num_iterations=100):
        # Build indices and interactions
        interactions = []
        for user_id, game_id, review in data:
            if user_id not in self.user_index:
                self.user_index[user_id] = len(self.user_index)
            if game_id not in self.game_index:
                self.game_index[game_id] = len(self.game_index)
            interactions.append((user_id, game_id, review["played"]))

        # Prepare sets for negative sampling
        all_games = list(self.game_index.keys())
        user_games = defaultdict(list)
        for user_id, game_id, _ in interactions:
            user_games[user_id].append(game_id)

        # BPR training step
        def train_step(model, interactions):
            num_samples = 50000
            with tf.GradientTape() as tape:
                sampled_users, sampled_pos_items, sampled_neg_items = [], [], []
                for _ in range(num_samples):
                    user_id, pos_item_id, _ = random.choice(interactions)
                    neg_item_id = random.choice(all_games)
                    while neg_item_id in user_games[user_id]:
                        neg_item_id = random.choice(all_games)

                    sampled_users.append(self.user_index[user_id])
                    sampled_pos_items.append(self.game_index[pos_item_id])
                    sampled_neg_items.append(self.game_index[neg_item_id])

                loss = model(sampled_users, sampled_pos_items, sampled_neg_items)
                loss += model.regularization_term()

            gradients = tape.gradient(loss, model.trainable_variables)
            optimizer.apply_gradients(zip(gradients, model.trainable_variables))
            return loss.numpy()

        optimizer = tf.keras.optimizers.Adam(0.1)
        self.bpr_model = BayesianPRModel(num_factors, 0.00001, self.game_index, self.user_index)

        for iteration in range(num_iterations):
            loss_value = train_step(self.bpr_model, interactions)
            if iteration % 10 == 9:
                print(f"Iteration {iteration+1}, Loss: {loss_value}")

        self.bpr_model.finalize_model()

    def predict_play(self, user, game, threshold=0.5):
        user_idx = self.user_index.get(user)
        game_idx = self.game_index.get(game)
        prediction_score = self.bpr_model.predict_single(user_idx, game_idx).numpy()
        return int(prediction_score > threshold)

# Initiate the GamePlayPredictor
game_play_predictor = GamePlayPredictor()

# Train the BPR model using the train_model method
num_factors = 6
num_iterations = 200  # Number of training iterations
game_play_predictor.train_model(train, num_factors=num_factors, num_iterations=num_iterations)

CM = np.array([[0,0], [0,0]])
balanced_valid = get_balanced_set(dataset, valid)
for user, game, review in balanced_valid:
    # Use the predict_play method from the GamePlayPredictor instance
    pred = game_play_predictor.predict_play(user, game, threshold=0.5)
    CM[review["played"]][pred] += 1

print("Confusion Matrix:")
print(CM)
print("GamePlayPredictor accuracy:", (CM[0][0] + CM[1][1]) / np.sum(CM))

# Function to write predictions to a file
def writePredictions(infile, outfile, game_play_predictor):
    with open(outfile, 'w') as predictions:
        for l in open(infile):
            if l.startswith("userID"):
                predictions.write(l)  # Write the header line
                continue
            u, g = l.strip().split(',')
            # Use the predict_play method for prediction
            pred = game_play_predictor.predict_play(u, g, threshold=0.5)
            predictions.write(u + ',' + g + ',' + str(pred) + '\n')

# Generate predictions for submission
writePredictions("/content/pairs_Played.csv", "/content/predictions_Played.csv", game_play_predictor)

"""Part 2"""

import gzip
import numpy as np
from collections import defaultdict
from sklearn.metrics import mean_squared_error
import random

def readJSON(path):
    for l in gzip.open(path, "rt", encoding='utf-8'):
        d = eval(l)
        yield (d['userID'], d['gameID'], d['hours_transformed'])  # Extract only userID, gameID, and hours_transformed

# Load and split the data
allHours = []
for u, g, h in readJSON("/content/train.json.gz"):  # Replace with your file path
    allHours.append((u, g, h))
random.shuffle(allHours)

hoursTrain = allHours[:165000]
hoursValid = allHours[165000:]

user_game_hours = defaultdict(dict)  # User's hours per game
game_user_hours = defaultdict(dict)  # Game's hours per user

for user, game, hours in allHours:
    user_game_hours[user][game] = hours
    game_user_hours[game][user] = hours

alpha = np.median([h for _, _, h in hoursTrain])  # Global average
betaU = defaultdict(float)  # User biases
betaI = defaultdict(float)  # Game biases

def iterate(lamb, alpha, betaU, betaI):
    new_betaU = defaultdict(float)
    new_betaI = defaultdict(float)

    for user in betaU:
        new_betaU[user] = sum([user_game_hours[user][game] - (alpha + betaI[game]) for game in user_game_hours[user]]) / (lamb + len(user_game_hours[user]))

    for game in betaI:
        new_betaI[game] = sum([game_user_hours[game][user] - (alpha + betaU[user]) for user in game_user_hours[game]]) / (lamb + len(game_user_hours[game]))

    a = sum(
        [user_game_hours[user][game] - (new_betaU[user] + new_betaI[game]) for user, game, _ in hoursTrain]
    ) / len(hoursTrain)

    return a, new_betaU, new_betaI

lamb = 5  # Regularization parameter
for _ in range(10):  # Number of iterations
    alpha, betaU, betaI = iterate(lamb, alpha, betaU, betaI)

preds = []
labels = []
for user, game, hours in hoursValid:
    pred = alpha + betaU[user] + betaI[game]
    preds.append(pred)
    labels.append(hours)

mse = mean_squared_error(labels, preds)
print(f"Mean Squared Error: {mse}")

with open("/content/predictions_Hours.csv", "w") as f:
    for l in open("/content/pairs_Hours.csv"):
        if l.startswith("userID"):
            f.write(l)
            continue
        u, g = l.strip().split(",")

        # Logic
        pred = (
            alpha
            + betaU.get(u, np.average([i for i in betaU.values()]))
            + betaI.get(g, np.average([i for i in betaI.values()]))
        )

        _ = f.write(u + "," + g + "," + str(pred) + "\n")
